<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>辞</title>
  
  <subtitle>迷雾里寻不见人, 那就把自己化作灯塔.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-02-01T11:50:55.440Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Ci</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>A Survey of the Applications of Sentiment Analysis</title>
    <link href="http://yoursite.com/2021/02/01/20210201-A-Survey-of-the-Applications-of-Sentiment-Analysis/"/>
    <id>http://yoursite.com/2021/02/01/20210201-A-Survey-of-the-Applications-of-Sentiment-Analysis/</id>
    <published>2021-02-01T09:11:00.000Z</published>
    <updated>2021-02-01T11:50:55.440Z</updated>
    
    <content type="html"><![CDATA[<h1 id="A-Survey-of-the-Applications-of-Sentiment-Analysis"><a href="#A-Survey-of-the-Applications-of-Sentiment-Analysis" class="headerlink" title="# A Survey of the Applications of Sentiment Analysis"></a># A Survey of the Applications of Sentiment Analysis</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="## Abstract"></a>## Abstract</h2><p>To help people understand sentiment analysis’s <code>application value</code>,</p><ul><li>survey various applications of sentiment analysis in <code>online business</code> and <code>offline business</code> as well as other types.</li><li>give some examples in intelligent customer service systems in China.</li><li>compare the applications of sentiment analysis on <code>Twitter</code>,<code>Weibo</code>,<code>Taobao</code> and <code>Facebook</code>, and discuss some challenges.</li><li>point out the <code>challenges</code> faced in the applications of sentiment analysis and valuable <code>future works</code>.</li></ul><br/><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="## Introduction"></a>## Introduction</h2><p>Sentiment analysis tasks involve many problems in the field of natural language processing, including <code>named entity recognition</code>(命名实体识别),<code>word polarity disambiguation</code>(词的极性消歧),<code>satire detection</code>(讽刺语检测), and <code>aspect extraction</code>(相位提取).</p><br/><p>In terms of granularity(粒度), We can classify sentiment analysis into:</p><ul><li><code>Fine-grained sentiment analysis</code>(细粒度的情感分析): refer to the sentiment analysis of <strong>phrases</strong> and <strong>words</strong>.</li><li><code>Coarse-grained sentimnet analysis</code>(粗粒度的情感分析): refer to the sentiment analysis of the overall propensity prediction of massive data sets at <strong>sentence level</strong> and <strong>chapter level</strong>.<ul><li>sentence-level</li><li>chapter-level</li><li>multiple-chapter-level</li></ul></li></ul><br/><p><code>explicit emotions</code> and <code>implicit emotions</code> according to whether or not the emotion is determinable. The current research mainly focuses on <strong>diaplaying sentiment analysis</strong>.</p><br/><p>The focus in this paper is not on surveying sentiment analysis methods, but on <strong>various applications of sentiment analysis in various domains</strong>, and particularly we discuss <strong>the challenges faced by sentiment analysis in their applications</strong> and <strong>the future development direction</strong>.<br><br/></p><h2 id="Online-Business"><a href="#Online-Business" class="headerlink" title="## Online Business"></a>## Online Business</h2><p>Mainly discuss some <code>commercial applications</code> of sentiment analysis.</p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn86w1qrdej30ia0lk755.jpg" style="zoom: 33%;" /><p>Online-Business:</p><ul><li>Product recommend &lt;商品推荐&gt;<ul><li>Likeness prediction &lt;画像预测&gt;</li><li>Intention prediction &lt;目的预测&gt;</li><li>Emend prediction &lt;改进预测&gt;</li></ul></li><li>Desion making &lt;决策制定&gt;<ul><li>Marketing strategy &lt;市场策略&gt;</li><li>Shoping decision &lt;营销策略&gt;</li></ul></li><li>Gojek review &lt;on Google store, a transport provider service provider&gt;</li><li>Intelligent customer service &lt;智能客服&gt;<ul><li>Ali Xiaomi </li><li>Alipay’s Xiaozuanfeng </li><li>Meituan group </li></ul></li></ul><br/><h2 id="Intelligent-Customer-Service-In-China"><a href="#Intelligent-Customer-Service-In-China" class="headerlink" title="## Intelligent Customer Service In China"></a>## Intelligent Customer Service In China</h2><h3 id="A-Ali-Xiaomi’s-Emotional-Recovery-Ability"><a href="#A-Ali-Xiaomi’s-Emotional-Recovery-Ability" class="headerlink" title="### A. Ali Xiaomi’s Emotional Recovery Ability"></a>### A. Ali Xiaomi’s Emotional Recovery Ability</h3><p>Ali Xiaomi uses the most commonly used seven classes of emotion words to <strong>comfort</strong> customers emotionally.</p><p>At present, Ali Xiaomi still <strong>has some problems with recognising weak emotions</strong>.</p><br/><h3 id="B-Intelligent-Customer-Service-of-Other-Platforms"><a href="#B-Intelligent-Customer-Service-of-Other-Platforms" class="headerlink" title="### B. Intelligent Customer Service of Other Platforms"></a>### B. Intelligent Customer Service of Other Platforms</h3><h4 id="Emotional-Recognition-of-the-Meituan-Group"><a href="#Emotional-Recognition-of-the-Meituan-Group" class="headerlink" title="#### Emotional Recognition of the Meituan Group"></a>#### Emotional Recognition of the Meituan Group</h4><p>The Meituan group tries to identify the emotions in <code>audio data</code> and <strong>develops a dialogue strategy based on the detected emotions</strong>.</p><br/><p>The research term of the Meituan group has now realised <code>the emotional recognition of audio</code> through <code>weak label learning</code>. </p><br/><p>Will continue to <strong>study multiple rounds of context modeling<code>(intentional understanding)</code></strong>, <strong>allowing users to make multiple-choice questions<code>(intended recommendations)</code></strong>, <strong>speech and text multimodality<code>(emotion recogintion)</code></strong>, <strong>historical topic extraction</strong>, <strong>segmentation<code>(seat assistant)</code></strong>, and so on. </p><br/><h4 id="Alipay’s-Xiaozuanfeng"><a href="#Alipay’s-Xiaozuanfeng" class="headerlink" title="#### Alipay’s Xiaozuanfeng"></a>#### Alipay’s Xiaozuanfeng</h4><p>For colloquial(口语化) questions, it is difficult for intelligent customer service based on <code>search engines</code> to give smart answers.</p><br/><p>The most significant advantage of Xiaozuanfeng is that it can <strong>learn by itself</strong>. The more question it answers, the more accurate its answers are.</p><br/><p>Xiaozuanfeng can identify a <strong>customer’s abusive feelings</strong> and appease the customer, but <strong>cannot detect other emotions</strong>.</p><br/><h2 id="Offline-Business"><a href="#Offline-Business" class="headerlink" title="## Offline Business"></a>## Offline Business</h2><p>Mainly discuss some <code>non-commercial applications</code> of sentiment analysis.</p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn88us0y4rj30jq0lu0ts.jpg" style="zoom: 33%;" /><p>Offline-Business:</p><ul><li><p>Prediction in social media </p><ul><li>Social network relationship prediction &lt;社交网络关系预测&gt;</li><li>event prediction &lt;事件预测&gt;</li></ul></li><li><p>Public opinion </p><ul><li>Opinion monitoring &lt;舆情监测&gt;</li><li>Risk analysis &lt;风险分析&gt;： through sentiment analysis, a company can quickly understand people’s general opinion trends on popular products, achieve effective prevention and response to various public opinion crises. </li></ul></li><li><p>Education</p><p>The main goal when performing sentiment analysis in the education field is to <strong>discover the negative emotions of students, and to adjust teaching methods in a timely manner before students are affected by negative emotions</strong>.</p><ul><li>Homework assessment and feedback &lt;作业评估与反馈&gt;</li><li>Curriculum level and dropout rate prediction &lt;课程水平及辍学率预测&gt;</li><li>university evaluation &lt;大学评价&gt;</li><li>Thesis quality assessment &lt;论文质量评估&gt;</li></ul></li><li><p>Healthcare</p></li><li><p>Smart city</p></li></ul><br/><h2 id="Other-Types-Of-Application"><a href="#Other-Types-Of-Application" class="headerlink" title="## Other Types Of Application"></a>## Other Types Of Application</h2><h3 id="Relationship-and-Event-Prediction"><a href="#Relationship-and-Event-Prediction" class="headerlink" title="### Relationship and Event Prediction"></a>### Relationship and Event Prediction</h3><ul><li>Social Network Relationship Prediction(社交网络关系预测)</li><li>Predictive Analysis of an event(事件预测)</li></ul><br/><h3 id="Dialogue-System"><a href="#Dialogue-System" class="headerlink" title="### Dialogue System"></a>### Dialogue System</h3><ul><li>CMN: for emotion recognition in dyadic dialogue videos.</li><li>ICON: an improved method of CMN.</li><li>DialogueRNN</li><li>IANN: for speech emotion recognition in speech dialogues.</li></ul><br/><h2 id="Discussions-And-Challenges"><a href="#Discussions-And-Challenges" class="headerlink" title="## Discussions And Challenges"></a>## Discussions And Challenges</h2><p>The current technology is still <strong>heavily dependent on the <code>quality of the input data</code></strong>, which means that <strong>recognizing the <em>double meaning</em> of <code>text</code>, <code>jokes</code> or <code>innuendos(暗讽)</code></strong> is a difﬁcult task for sentiment analysis.</p><br/><p>Table V compares the <strong>appilcations of sentiment analysis</strong> on <code>Twitter</code>, <code>Weibo</code>, <code>Taobao</code>, and <code>Facebook</code>.</p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn89tdkt1vj30ni0xqgpo.jpg" style="zoom:67%;" /><br/><p>Table VI compares the <strong>applications on specific fields</strong> such as <code>Hotel</code>, <code>Movie</code>, <code>Restaurant</code>, and <code>Tourism</code>.</p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn89tqo7slj30mg0imjtq.jpg" style="zoom:67%;" /><br/><h2 id="Conclusions-And-Future-Work"><a href="#Conclusions-And-Future-Work" class="headerlink" title="## Conclusions And Future Work"></a>## Conclusions And Future Work</h2><p>This paper surveys <strong>applications of sentiment analysis</strong> in: <code>business</code>,<code>intelligent customer service</code>,<code>public opinion mining and risk analysis</code>,<code>education</code>,<code>medical care</code>,<code>smart city</code>,<code>relationship and event prediction</code>, and <code>dialogue systems</code>. </p><br/><p>The applications of sentiment analysis on <code>non-English texts and available resources</code> are still relatively few. Such as <code>Arabic</code>(阿拉伯语), <code>Spanish</code> and <code>Chinese</code>.  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;A-Survey-of-the-Applications-of-Sentiment-Analysis&quot;&gt;&lt;a href=&quot;#A-Survey-of-the-Applications-of-Sentiment-Analysis&quot; class=&quot;headerlink&quot;
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/categories/paper/"/>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="sentiment analysis" scheme="http://yoursite.com/tags/sentiment-analysis/"/>
    
      <category term="survey" scheme="http://yoursite.com/tags/survey/"/>
    
  </entry>
  
  <entry>
    <title>Word2Vec词向量-CBOW模型</title>
    <link href="http://yoursite.com/2021/01/31/20210131-Word2Vec%E8%AF%8D%E5%90%91%E9%87%8F-CBOW%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2021/01/31/20210131-Word2Vec%E8%AF%8D%E5%90%91%E9%87%8F-CBOW%E6%A8%A1%E5%9E%8B/</id>
    <published>2021-01-31T11:42:00.000Z</published>
    <updated>2021-01-31T12:18:14.175Z</updated>
    
    <content type="html"><![CDATA[<p>转载:[<a href="https://www.zhihu.com/question/44832436/answer/266068967]" target="_blank" rel="noopener">https://www.zhihu.com/question/44832436/answer/266068967]</a></p><h2 id="Word2Vec得到词向量"><a href="#Word2Vec得到词向量" class="headerlink" title="Word2Vec得到词向量"></a>Word2Vec得到词向量</h2><p>文本语料库进行预处理，得到processed corpus，将它们的one-hot向量作为Word2Vec的输入，通过Word2Vec训练低维词向量(word embedding).</p><p>Word2Vec主要有两种训练模型CBOW和Skip-gram. 两种加速算法Negative Sample和Hierarchical Softmax.</p><h2 id="One-hot-Vector-gt-Word2Vec-gt-低维词向量"><a href="#One-hot-Vector-gt-Word2Vec-gt-低维词向量" class="headerlink" title="One-hot Vector -&gt; (Word2Vec) -&gt; 低维词向量"></a>One-hot Vector -&gt; (Word2Vec) -&gt; 低维词向量</h2><p>CBOW: 由中心词周围的词来预测中心词.</p><p>Skip-gram: 由中心词来预测周围的词.</p><h3 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h3><img src="https://pic2.zhimg.com/v2-2a319bac1bb7fcae2f4395d2c38674ea_r.jpg?source=1940ef5c" style="zoom:48%;" /><img src="https://pic2.zhimg.com/80/v2-0f439e1bb44c71c8e694cc65cb509263_1440w.jpg?source=1940ef5c" style="zoom:50%;" /><ol><li>输入层：为上下文单词的one-hot vector.「假设单词向量空间维度dim为V，上下文单词数为C」</li><li>所有one-hot向量分别乘以共享的权重矩阵W. 「V*N矩阵，N为自己设定的数，初始化权重矩阵W」</li><li>所得的向量相加求平均作为隐藏层向量，size为1*N</li><li>乘以输出权重矩阵W’ 「W’为N*V维矩阵」</li><li>得到向量「1*V」激活函数处理得到V-dim概率分布，概率最大的index所指示的单词为预测出的中间词(target word)</li><li>与true label的one-hot相比较，误差越小越好</li></ol><p>因此，需要定义loss function(一般为交叉熵代价函数)，采用梯度下降算法更新W和W’。</p><p>训练完毕后，输入层的每个单词与矩阵W(look up table)相乘得到的向量就是所要的词向量(word embedding)。即任何一个单词的one-hot乘以这个矩阵都将得到自己的词向量。</p><p>有了look up table就可以免去训练过程直接查表得到单词的词向量了。</p><h4 id="Example-of-CBOW-Model"><a href="#Example-of-CBOW-Model" class="headerlink" title="Example of CBOW Model"></a>Example of CBOW Model</h4><p><img src="https://pic3.zhimg.com/v2-3e75211b3b675f17a232f29fae0982bc_r.jpg?source=1940ef5c" alt=""></p><p><img src="https://pic1.zhimg.com/v2-abd3c7d6bc76c01266e8ddd32acfe31a_r.jpg?source=1940ef5c" alt=""></p><p><img src="https://pic2.zhimg.com/v2-66655880a87789eaba5dd6f5c5033e94_r.jpg?source=1940ef5c" alt=""></p><p><img src="https://pic1.zhimg.com/v2-5325f4a5d1fbacefd93ccb138b706a69_r.jpg?source=1940ef5c" alt=""></p><p><img src="https://pic4.zhimg.com/v2-1713450fa2a0f37c8cbcce4ffef04baa_r.jpg?source=1940ef5c" alt=""></p><p>假设我们此时得到的概率分布已经达到了设定的迭代次数，那么现在我们训练出来的look up table应该为矩阵W。即，<strong>任何一个单词的one-hot表示乘以这个矩阵都将得到自己的word embedding。</strong></p><h3 id="Skip-gram"><a href="#Skip-gram" class="headerlink" title="Skip-gram"></a>Skip-gram</h3><img src="https://pic3.zhimg.com/v2-a54db7c984e6eaf9f06cf21178238fc6_r.jpg?source=1940ef5c" style="zoom:48%;" /> ]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;转载:[&lt;a href=&quot;https://www.zhihu.com/question/44832436/answer/266068967]&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.zhihu.com/question/448
      
    
    </summary>
    
    
      <category term="NLP" scheme="http://yoursite.com/categories/NLP/"/>
    
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="embedding" scheme="http://yoursite.com/tags/embedding/"/>
    
  </entry>
  
  <entry>
    <title>Sentiment Analysis using Deep Learning – A survey</title>
    <link href="http://yoursite.com/2021/01/31/20210131-Sentiment-Analysis-using-Deep-Learning-%E2%80%93-A-survey/"/>
    <id>http://yoursite.com/2021/01/31/20210131-Sentiment-Analysis-using-Deep-Learning-%E2%80%93-A-survey/</id>
    <published>2021-01-31T11:06:00.000Z</published>
    <updated>2021-01-31T15:12:49.699Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Sentiment-Analysis-using-Deep-Learning-–-A-survey"><a href="#Sentiment-Analysis-using-Deep-Learning-–-A-survey" class="headerlink" title="Sentiment Analysis using Deep Learning – A survey"></a>Sentiment Analysis using Deep Learning – A survey</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>In this paper, they are going to </p><ul><li>perform multi-class sentiment analysis using Deep learning models like LSTM and C-LSTM on textual data</li><li>see its results as compared to other Machine learning models</li><li>carry out parameter tuning using Dropout regularization to analyze its effect on the accuracy of the model</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In this paper, they are going to perform a <code>multi-class sentiment analysis</code> using <code>Deep Learning</code> on amazon product review data.</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>Three techniques for Sentiment Analysis: <code>Lexicon based</code>,<code>Machine Learning</code> and <code>Deep Learning</code>.</p><p>Machine Learning </p><ul><li>Supervised Learning<ul><li>Classification</li><li>Regression</li></ul></li><li>Unsupervised Learning <ul><li>Clustering</li></ul></li></ul><p>With the increase in the amount of diversified(多样化的) data to be processed, Machine Learning cannot cope up with the performance. Hence, Deep Learning came into the picture.</p><p>Deep Learning</p><ul><li>Convolution Neural Network(CNN)</li><li>Recurrent Neural Network(RNN)</li><li>Long Short Term Memory(LSTM)</li><li>…</li></ul><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn73k1oo4kj312a0h4gnh.jpg" style="zoom: 50%;" /><p>In this paper, they are incorporating(合并) the Word2Vec using the CBOW(Common Bag-of-words) embedding model. </p><h2 id="Proposed-Methodology"><a href="#Proposed-Methodology" class="headerlink" title="Proposed Methodology"></a>Proposed Methodology</h2><h3 id="Dataset-Description"><a href="#Dataset-Description" class="headerlink" title="Dataset Description"></a>Dataset Description</h3><p>The file is in a CSV format consisting of 6,50,000 reviews and ratings. Each review has a rating that is in the range from 1 to 5.</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn77i1hfk1j30iw0860te.jpg" alt=""></p><h3 id="One-hot-encoding"><a href="#One-hot-encoding" class="headerlink" title="One-hot-encoding"></a>One-hot-encoding</h3><p>The data in the <code>rating column</code> is <code>label encoded</code> which may confuse the model while training, hence it is <code>one-hot-encoded</code>.</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn77hz09mbj30iw0860us.jpg" alt=""></p><h3 id="Preprocessing-and-Tokenization"><a href="#Preprocessing-and-Tokenization" class="headerlink" title="Preprocessing and Tokenization"></a>Preprocessing and Tokenization</h3><p>preprocessing: <code>converting the text in lower-case</code>,<code>eliminating punctuation,numbers,special characters and stop words</code></p><p>Tokenization: <code>break the text into tokens</code>.</p><p>E.g:</p><p>[[‘model’,’may’,’ok’,’sedentary’,’types’ ,’active’,’get’,’around’,’alot’,’job’,’c onsistently’,’found’,’stockings’,’rolled ‘,’ankles’,’good’,’solution’,’go’,’stand ard’,’compression’,’stocking’,’stock’,’e xcellent’,’support’,’stays’,’gives’,’nee d’,’pair’,’also’,’tore’,’struggled’,’pul l’,’time’,’good’,’riddancebad’,’investme nt’]]</p><h3 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h3><p>A process of <strong>converting the word representations to vectors</strong>. (<code>Word2Vec model</code> and <code>GloVe model</code>)</p><p>本文使用的是<code>Word2Vec</code> using the <code>Continuous Bag of Words(CBOW) model</code>.</p><h3 id="Padding-and-Splitting"><a href="#Padding-and-Splitting" class="headerlink" title="Padding and Splitting"></a>Padding and Splitting</h3><p>The length of the reviews is not the same. So they <code>keep the length of the text sequence equal</code> by <code>padding zeros</code> at the end(post-padding) or at the beginning(pre-padding).</p><p>Data:  80%-training set | 20%-validation set</p><h3 id="Recurrent-Neural-Network-RNN"><a href="#Recurrent-Neural-Network-RNN" class="headerlink" title="Recurrent Neural Network(RNN)"></a>Recurrent Neural Network(RNN)</h3><p>RNN has memory. The major drawback of RNN is the <code>Vanishing gradient</code> problem.</p><p>(“half part of the network which is closer to the output is updated” and “another half part away from the output is not updated properly”)</p><h3 id="Long-Short-Term-Memory-LSTM"><a href="#Long-Short-Term-Memory-LSTM" class="headerlink" title="Long Short Term Memory(LSTM)"></a>Long Short Term Memory(LSTM)</h3><p>To overcome the vanishing gradient problem of RNN, Long Short Term Memory(LSTM) is implemented.</p><p>This paper uses <code>CuDNNLSTM</code> model which uses a <code>Deep Neural network using CUDA</code>.</p><p><code>CuDNN</code> library aids in <code>fast processing with the help of parallel processing GPU</code>. </p><p>The model is compiled using <code>Adam optimizer</code> having  <code>categorical cross-entropy</code> as the value of the <code>loss gradient</code>.</p><h3 id="C-LSTM"><a href="#C-LSTM" class="headerlink" title="C-LSTM"></a>C-LSTM</h3><p>The advange of <code>CNN</code> to <strong>determine local features</strong> and that of <code>LSTM</code> to <strong>interpret the sequential information</strong> can be combined in the <code>C-LSTM</code> model.</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn78ii2perj30rw0dagmn.jpg" alt=""> </p><h2 id="Experiments-And-Results"><a href="#Experiments-And-Results" class="headerlink" title="Experiments And Results"></a>Experiments And Results</h2><h3 id="Changing-the-dataset"><a href="#Changing-the-dataset" class="headerlink" title="Changing the dataset"></a>Changing the dataset</h3><p><strong>Dataset 1</strong>: A Yelp data set consisting of 6,40,000 reviews and having columns reviews and ratings. Each Rating category in this data set has 1,30,00 reviews.</p><p><strong>Dataset 2</strong>: Amazon Home &amp; Appliances containing 5,51682 reviews and ratings.</p><p><strong>Dataset 3</strong>: Amazon general product reviews consisting of 6,50,000 reviews and ratings. Each review has a rating that is in the range from 1 to 5.</p><p><code>C-LSTM Model</code></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn796uujfvj30k006st98.jpg" alt=""> </p><h3 id="Machine-Learning-models"><a href="#Machine-Learning-models" class="headerlink" title="Machine Learning models"></a>Machine Learning models</h3><p><code>LSTM and C-LSTM</code> in Comparison with <code>machine learning algorithms</code> like <strong>SVM</strong> and <strong>Baive Bayes</strong>. </p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn79dqeyv9j30jq08kt9h.jpg" alt=""></p><h3 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h3><p>The diagonal elements(对角线元素) in the matrix specify the counts of reviews that are classified correctly. </p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn79o51q6gj30ey0ci0tg.jpg" style="zoom: 50%;" /><h3 id="Changing-Dropout-Regularization"><a href="#Changing-Dropout-Regularization" class="headerlink" title="Changing Dropout Regularization"></a>Changing Dropout Regularization</h3><p><code>Increasing the number of epochs</code> may lead to <code>overfitting</code>. Hence <code>dropout regularization</code> is used to overcome the problem of overfitting. </p><p>Some of the neurons are disabled randomly to prevent them from being too dependent on one another. </p><p>They gradually change the dropout rate to analyze its effect on accuracy on the LSTM model. </p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn79xbmtqpj30no0bkq42.jpg" style="zoom:50%;" /><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>The results show that:</p><ul><li><code>deep learning</code> is superior to <code>machine learning</code>. </li><li><code>C-LSTM model</code> outperforms the <code>LSTM model</code>.</li><li>conducted parameter tuning techniques like <code>changing the rate of the dropout</code>.</li><li>it is the <code>quality of data</code> that determines the <code>quality of the result</code>.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Sentiment-Analysis-using-Deep-Learning-–-A-survey&quot;&gt;&lt;a href=&quot;#Sentiment-Analysis-using-Deep-Learning-–-A-survey&quot; class=&quot;headerlink&quot; t
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/categories/paper/"/>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="sentiment analysis" scheme="http://yoursite.com/tags/sentiment-analysis/"/>
    
      <category term="survey" scheme="http://yoursite.com/tags/survey/"/>
    
  </entry>
  
  <entry>
    <title>Survey Paper on Sentiment Analysis - Techniques and Challenges</title>
    <link href="http://yoursite.com/2021/01/31/20210131-Survey-Paper-on-Sentiment-Analysis---Techniques-and-Challenges/"/>
    <id>http://yoursite.com/2021/01/31/20210131-Survey-Paper-on-Sentiment-Analysis---Techniques-and-Challenges/</id>
    <published>2021-01-31T01:36:00.000Z</published>
    <updated>2021-01-31T03:58:04.312Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>In this paper, they are going:</p><ul><li>to survey different steps and techniques on sentiment analysis. </li><li>to find out a better way to increase the accuracy and efficiency of a model.</li><li>to discuss various challenges in sentiment analysis.</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Reviews helps the potential user to understand the product from inside out.</p><p>Finding the suitable techniques to analyse the reviews is the main objective of this paper.</p><p>Sentiment analysis can be carried out by two approaches i.e. <code>machine learning approach</code> and <code>lexicon based approach</code>. </p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn6n5p4lryj30t60midjx.jpg" style="zoom: 50%;" /><h3 id="Data-Acquisition"><a href="#Data-Acquisition" class="headerlink" title="Data Acquisition"></a>Data Acquisition</h3><p>Use a web scraper <code>beautiful soup</code> to extract the reviews from webpages. </p><h3 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h3><p>The extracted reviews of a product are in the form of either <code>sentences</code> or <code>paragraphs</code>.</p><p>Basically data preprocessing include <code>tokenization</code>, <code>stop-words removal</code>, <code>stemming</code>(词干提取) and <code>lemmatization</code>(词元化).</p><h4 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h4><p>Dividing the <code>paragraphs into sentences</code> and <code>sentences into words</code>.</p><p><code>Word tokenizer</code>: tokenize the sentence into words.</p><p><code>sentence tokenizer</code>: tokenize the paragraph into sentences.</p><h4 id="Stop-words-Removal"><a href="#Stop-words-Removal" class="headerlink" title="Stop-words Removal"></a>Stop-words Removal</h4><p><code>Stop-words</code> are words that are not considered or do not contribute in the analysis process. (better to remove rather than storing)</p><h4 id="Stemming-and-Lemmatization"><a href="#Stemming-and-Lemmatization" class="headerlink" title="Stemming and Lemmatization"></a>Stemming and Lemmatization</h4><p><code>Steamming</code> is the process of finding out morphemes(词素) or the root words from the derived words. (not give the actual morphemes but the closest one)</p><ul><li><code>morphemes</code>: In English grammar and morphology, a morpheme is a meaningful linguistic unit consisting of a word such as dog, or a word element, such as the -s at the end of dogs, that can’t be divided into smaller meaningful parts. Morphemes are the smallest units of meaning in a language</li></ul><p><code>Lemmatization</code> gives the actual root word by comparing the stemmed words in its dictionary and gives the closest actual one. </p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn6ourb07pj30ik04gdg0.jpg" style="zoom:67%;" /><h3 id="Analyzed-Output"><a href="#Analyzed-Output" class="headerlink" title="Analyzed Output"></a>Analyzed Output</h3><p>reviews -&gt; (preprocessing step) -&gt; tokens -&gt; (various algorithms) -&gt; output in the form of rating</p><h2 id="Sentiment-Classification-Techniques"><a href="#Sentiment-Classification-Techniques" class="headerlink" title="Sentiment Classification Techniques"></a>Sentiment Classification Techniques</h2><p><code>Lexicon based approach</code>, <code>Machine learning approach</code> and <code>Hybrid approach</code> are the classification of Sentiment Analysis.</p><h3 id="Lexicon-based-approach"><a href="#Lexicon-based-approach" class="headerlink" title="Lexicon based approach"></a>Lexicon based approach</h3><p><code>Lexicon based approach</code> divides the entire document into lexemes(词素) which is used to examine the sentences.</p><p>[<a href="https://zhuanlan.zhihu.com/p/106588589]" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/106588589]</a></p><p>人工构建词典是抓取数据之后多次进行人工标注，根据情感表达将词语进行正负向和强弱程度区分。</p><ul><li><p><code>corpus based approach</code>(基于语料库的方法): It is <code>less efficient</code> than dictionary based approach because <code>making a large corpus for covering English words</code> is a difficult task.</p><p>完备的语义知识库, 能够快速构建通用性较强的情感词典, 对词典的精度要求不高的情况下, 这种方法较为实用。中文语义知识库的不足以及领域的限制使得该方法在构建面向单一领域的情感词典中表现不佳。</p></li><li><p><code>dictionary based approach</code>(基于词典的方法): <code>Better efficency</code>. It uses a dictionary which consists of all the synonyms and antonyms of each words. </p><p>相对于语义知识库而言, 其优点是容易获得且数量充足, 构建的词典在语料所属的领域内表现较好, 但是构建的成本较高, 需要对语料进行预处理, 另外, 所构建的词典的准确率相对不高。</p></li></ul><h3 id="Machine-learning-approach"><a href="#Machine-learning-approach" class="headerlink" title="Machine learning approach"></a>Machine learning approach</h3><p>基于词典的文本情感分析技术由于构建的词典往往<strong>只针对某个领域</strong>，对于跨领域情感分析的效果不够好，而且词典中的情感词可能不够丰富，对于短文本和特定领域文本进行情感分析的效果更好。因此，对于长文本来说，更好的解决方法是利用机器学习方法。</p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn6q3mhnghj30zg0i4q4c.jpg" style="zoom: 33%;" /><ul><li><p><code>Naive Bayes algorithm</code>: Bayes’ theorem computes the probability of given set using already calculated probabilities.</p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn6ps72guij30ke0buaak.jpg" style="zoom: 33%;" /><p>(基于公式可得出x归为情感C的概率).</p></li><li><p><code>Maximum entropy</code>(最大熵): 基于最大熵的文本情感分析只要得到一些训练数据，然后进行迭代，就可以得到所需模型，进行自收敛，方法简单。但是由于最大熵往往只能得到局部最佳解而非全局最优解，因此运用该方法进行情感分析准确率有待提高。且约束函数数量和样本数目有关系，导致迭代过程计算量巨大，实际应用比较难。</p></li><li><p><code>Support Vector Machines</code>: 通过寻求结构化风险最小以提高学习机泛化能力，实现经验风险和置信范围的最小化，从而达到在统计样本量较少的情况下，亦能获得良好统计规律的目的。但该方法对参数调节和核函数的选择敏感。</p></li></ul><h3 id="Deep-learning"><a href="#Deep-learning" class="headerlink" title="Deep learning"></a>Deep learning</h3><p>随着深度学习的快速发展, 词向量模型等的提出恰好为相关研究提供了契机。</p><p>在深度学习中，可以应用于情感分析的技术有很多，比如：</p><ul><li>前馈神经网络(FNN)</li><li>Word2Vec词嵌入技术</li><li>卷积神经网络(CNN)</li><li>循环神经网络(RNN)</li><li>LSTM网络</li></ul><h2 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h2><h3 id="Multiple-Language-Input"><a href="#Multiple-Language-Input" class="headerlink" title="Multiple Language Input"></a>Multiple Language Input</h3><p>The classifier mainly uses <code>English language</code> while the reviews given by users can be in <code>multiple languages</code>. </p><h3 id="Fake-Inputs"><a href="#Fake-Inputs" class="headerlink" title="Fake Inputs"></a>Fake Inputs</h3><p>Fake or bogus reviwes misguide the users or customers about a product by providing <code>fake</code> or <code>irrelevant</code> nagative or positive reviews, to increase or decrease to the popularity of a product. </p><h3 id="Emoticons-and-Sarcastic-Reviews"><a href="#Emoticons-and-Sarcastic-Reviews" class="headerlink" title="Emoticons and Sarcastic Reviews"></a>Emoticons and Sarcastic Reviews</h3><p><code>Emoticons</code>(表情符号) are the pictorial representation of one’s expressions while it becomes difficult for a machine to understand the emoticons. </p><p><code>Sarcastic reviews</code>(讽刺性评论) are difficult to interpret by the machine. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;In this paper, they are going:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;to
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/categories/paper/"/>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="sentiment analysis" scheme="http://yoursite.com/tags/sentiment-analysis/"/>
    
      <category term="survey" scheme="http://yoursite.com/tags/survey/"/>
    
  </entry>
  
  <entry>
    <title>pip更换镜像源</title>
    <link href="http://yoursite.com/2021/01/31/20210131-pip:Anaconda%E6%9B%B4%E6%8D%A2%E9%95%9C%E5%83%8F%E6%BA%90/"/>
    <id>http://yoursite.com/2021/01/31/20210131-pip:Anaconda%E6%9B%B4%E6%8D%A2%E9%95%9C%E5%83%8F%E6%BA%90/</id>
    <published>2021-01-31T00:41:00.000Z</published>
    <updated>2021-01-31T00:49:10.399Z</updated>
    
    <content type="html"><![CDATA[<h2 id="国内镜像源"><a href="#国内镜像源" class="headerlink" title="国内镜像源"></a>国内镜像源</h2><p>清华：<a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a><br>阿里云：<a href="http://mirrors.aliyun.com/pypi/simple/" target="_blank" rel="noopener">http://mirrors.aliyun.com/pypi/simple/</a><br>中国科技大学 <a href="https://pypi.mirrors.ustc.edu.cn/simple/" target="_blank" rel="noopener">https://pypi.mirrors.ustc.edu.cn/simple/</a><br>华中理工大学：<a href="http://pypi.hustunique.com/" target="_blank" rel="noopener">http://pypi.hustunique.com/</a><br>山东理工大学：<a href="http://pypi.sdutlinux.org/" target="_blank" rel="noopener">http://pypi.sdutlinux.org/</a><br>豆瓣：<a href="http://pypi.douban.com/simple/" target="_blank" rel="noopener">http://pypi.douban.com/simple/</a></p><h2 id="指定某资源库下载时使用某镜像"><a href="#指定某资源库下载时使用某镜像" class="headerlink" title="指定某资源库下载时使用某镜像"></a>指定某资源库下载时使用某镜像</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将从清华的镜像下载pyspider库</span></span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pyspider</span><br></pre></td></tr></table></figure><h2 id="永久修改"><a href="#永久修改" class="headerlink" title="永久修改"></a>永久修改</h2><p>linux/macOS下，修改<code>~/.pip/pip.conf</code>：</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="meta">global</span>]</span><br><span class="line">index-url = https:<span class="comment">//pypi.tuna.tsinghua.edu.cn/simple</span></span><br><span class="line">[<span class="meta">install</span>]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></table></figure><p>windows下，直接在user目录中创建一个pip目录，再新建文件pip.ini。（例如：C:\Users\Administrator\pip\pip.ini）内容同上。</p><h2 id="Anaconda修改镜像源"><a href="#Anaconda修改镜像源" class="headerlink" title="Anaconda修改镜像源"></a>Anaconda修改镜像源</h2><p>中科大</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda config --<span class="keyword">add</span> channels https:<span class="comment">//mirrors.ustc.edu.cn/anaconda/pkgs/free/  </span></span><br><span class="line">conda config --<span class="keyword">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure><p>清华</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda config --<span class="keyword">add</span> channels https:<span class="comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span></span><br><span class="line">conda config --<span class="keyword">add</span> channels https:<span class="comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span></span><br><span class="line">conda config --<span class="keyword">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure><p>或者直接修改<code>~/.condarc</code>文件内容：</p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn6l8vjt7lj30vo0mymys.jpg" style="zoom:67%;" />]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;国内镜像源&quot;&gt;&lt;a href=&quot;#国内镜像源&quot; class=&quot;headerlink&quot; title=&quot;国内镜像源&quot;&gt;&lt;/a&gt;国内镜像源&lt;/h2&gt;&lt;p&gt;清华：&lt;a href=&quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot; targ
      
    
    </summary>
    
    
      <category term="tips" scheme="http://yoursite.com/categories/tips/"/>
    
    
      <category term="tips" scheme="http://yoursite.com/tags/tips/"/>
    
  </entry>
  
  <entry>
    <title>conda报错-There appear to be 1 leaked semaphore objects to clean up at shutdown</title>
    <link href="http://yoursite.com/2021/01/30/20210131-conda%E6%8A%A5%E9%94%99-There-appear-to-be-1-leaked-semaphore-objects-to-clean-up-at-shutdown/"/>
    <id>http://yoursite.com/2021/01/30/20210131-conda%E6%8A%A5%E9%94%99-There-appear-to-be-1-leaked-semaphore-objects-to-clean-up-at-shutdown/</id>
    <published>2021-01-30T15:58:00.000Z</published>
    <updated>2021-01-31T00:52:42.705Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>安装Anaconda后运行<code>conda env list</code>时报警告⚠️如下：</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gn673z4kxej30vo08wta2.jpg" alt=""></p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>使用<code>conda update --all</code>命令</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;p&gt;安装Anaconda后运行&lt;code&gt;conda env list&lt;/code&gt;时报警告⚠️如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;htt
      
    
    </summary>
    
    
      <category term="tips" scheme="http://yoursite.com/categories/tips/"/>
    
    
      <category term="tips" scheme="http://yoursite.com/tags/tips/"/>
    
  </entry>
  
  <entry>
    <title>Error:Could not install packages due to an EnvironmentError-Errno 28 No space left on device</title>
    <link href="http://yoursite.com/2021/01/28/20210128-ErrorCould-not-install-packages-due-to-an-EnvironmentError-Errno-28-No-space-left-on-device/"/>
    <id>http://yoursite.com/2021/01/28/20210128-ErrorCould-not-install-packages-due-to-an-EnvironmentError-Errno-28-No-space-left-on-device/</id>
    <published>2021-01-28T08:11:00.000Z</published>
    <updated>2021-01-28T09:04:39.870Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Error-Info"><a href="#Error-Info" class="headerlink" title="Error Info"></a>Error Info</h2><p>pip install的时候报错：</p><p><strong>Error</strong>: Could not install packages due to an EnvironmentError: [Errno 28] No space left on device</p><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>查看磁盘空间</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn3hbhaalfj30ui094myo.jpg" alt=""></p><p>看到挂载点/devdata还有1.4T空间，不是磁盘空间不够。</p><p>可能由于缓存空间不够了，即设备分配给/tmp的磁盘空间不够了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(lisaipeng) xddz@xddz:&#x2F;devdata$ cd &#x2F;tmp</span><br><span class="line">(lisaipeng) xddz@xddz:&#x2F;tmp$ ls</span><br><span class="line">(lisaipeng) xddz@xddz:&#x2F;tmp$ rm -rf *</span><br></pre></td></tr></table></figure><p>清空/tmp空间后(挂载点/空间清理出174M)，pip install仍报错设备空间不够。</p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn3hlz4ejsj30mq08ut9u.jpg" style="zoom:67%;" /><p>猜测，尽管将pip install安装包路径指定到/devdata中，但是仍需要/挂载点的空间用作安装包缓存。因此仍然需要清理/挂载点空间。</p><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>使用如下命令，查看设备空间使用情况(各一级文件夹占用)。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) xddz@xddz:~$ du -h --max-depth&#x3D;1</span><br></pre></td></tr></table></figure><p>将大文件夹移动到/devdata挂载点。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) xddz@xddz:/devdata$ mv -r /home/xddz/Downloads /devdata/Downloads</span><br></pre></td></tr></table></figure><p>清理出9G空间。</p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn3hsdp621j30n009275k.jpg" style="zoom:67%;" /><p>再次pip install, 可以正常安装包了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Error-Info&quot;&gt;&lt;a href=&quot;#Error-Info&quot; class=&quot;headerlink&quot; title=&quot;Error Info&quot;&gt;&lt;/a&gt;Error Info&lt;/h2&gt;&lt;p&gt;pip install的时候报错：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Error
      
    
    </summary>
    
    
      <category term="tip" scheme="http://yoursite.com/categories/tip/"/>
    
    
      <category term="tip" scheme="http://yoursite.com/tags/tip/"/>
    
  </entry>
  
  <entry>
    <title>服务器conda创建指定路径虚拟环境时，不显示名称无法找到</title>
    <link href="http://yoursite.com/2021/01/28/20210128-%E6%9C%8D%E5%8A%A1%E5%99%A8conda%E5%88%9B%E5%BB%BA%E6%8C%87%E5%AE%9A%E8%B7%AF%E5%BE%84%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E6%97%B6%EF%BC%8C%E4%B8%8D%E6%98%BE%E7%A4%BA%E5%90%8D%E7%A7%B0%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0/"/>
    <id>http://yoursite.com/2021/01/28/20210128-%E6%9C%8D%E5%8A%A1%E5%99%A8conda%E5%88%9B%E5%BB%BA%E6%8C%87%E5%AE%9A%E8%B7%AF%E5%BE%84%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E6%97%B6%EF%BC%8C%E4%B8%8D%E6%98%BE%E7%A4%BA%E5%90%8D%E7%A7%B0%E6%97%A0%E6%B3%95%E6%89%BE%E5%88%B0/</id>
    <published>2021-01-28T06:47:00.000Z</published>
    <updated>2021-01-28T08:10:44.680Z</updated>
    
    <content type="html"><![CDATA[<h2 id="指定路径conda虚拟环境"><a href="#指定路径conda虚拟环境" class="headerlink" title="指定路径conda虚拟环境"></a>指定路径conda虚拟环境</h2><p>创建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create --prefix=/root/python36/venv-name python=<span class="number">3.6</span><span class="number">.8</span></span><br></pre></td></tr></table></figure><p>删除</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda remove -p /root/python36/venv-name --all</span><br></pre></td></tr></table></figure><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>创建的conda环境不显示名称，且找不到也无法激活(activate).</p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn3eu5m15fj30nm06mdgl.jpg" style="zoom:67%;" /><p><code>conda activate lisaipeng</code>会提示无法找到该环境。</p><h2 id="解决途径"><a href="#解决途径" class="headerlink" title="解决途径"></a>解决途径</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda config --add pkgs_dirs /devdata/saipeng.li/pkgs</span><br><span class="line">conda config --add envs_dirs /devdata/saipeng.li/envs</span><br></pre></td></tr></table></figure><p>查看conda info</p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn3f1ceo3aj30j404ijrt.jpg" style="zoom:67%;" /><p>查看conda env list</p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn3f24fxawj30no05ogm1.jpg" style="zoom:67%;" /><p>get it.</p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>所创建的conda虚拟环境的pip install会将包安装在全局pip路径下，应该在虚拟环境中安装pip，将其安装到自己的虚拟环境目录中.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pip</span><br></pre></td></tr></table></figure><p>~/.bashrc中添加：</p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn3gk43rblj30mw0140ta.jpg" alt="image-20210128154953128" style="zoom:50%;" /><p>(lisaipeng) xddz@xddz:/devdata/saipeng.li/envs/lisaipeng/lib/python3.6$ vi site.py</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn3gw3unh0j30v001ywg5.jpg" alt=""></p><p>查看python site-info.</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gn3gxx73hhj310209udn1.jpg" alt="image-20210128160309113"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;指定路径conda虚拟环境&quot;&gt;&lt;a href=&quot;#指定路径conda虚拟环境&quot; class=&quot;headerlink&quot; title=&quot;指定路径conda虚拟环境&quot;&gt;&lt;/a&gt;指定路径conda虚拟环境&lt;/h2&gt;&lt;p&gt;创建&lt;/p&gt;
&lt;figure class=&quot;high
      
    
    </summary>
    
    
      <category term="tips" scheme="http://yoursite.com/categories/tips/"/>
    
    
      <category term="tips" scheme="http://yoursite.com/tags/tips/"/>
    
  </entry>
  
  <entry>
    <title>SPC(Single-pass Clsutering)</title>
    <link href="http://yoursite.com/2021/01/26/20210126-SPC(Single-pass-Clsutering)/"/>
    <id>http://yoursite.com/2021/01/26/20210126-SPC(Single-pass-Clsutering)/</id>
    <published>2021-01-26T06:50:00.000Z</published>
    <updated>2021-01-27T08:38:13.505Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Single-pass-Clustering"><a href="#Single-pass-Clustering" class="headerlink" title="Single-pass Clustering"></a>Single-pass Clustering</h2><p>在文本主题聚类中，single-pass clustering(单遍聚类)算法通常比K-means更为有效。每个文档只需要流过算法一次，其不需要指定类目数量，可以通过设定相似度阈值来限定聚类数量。</p><h3 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h3><p>Single-pass算法顺序地处理文本</p><ol><li><strong>以第一篇文档为种子，建立一个新主题</strong>。</li><li>计算新进入文档与已有主题的<strong>相似度</strong>：<ul><li>如果与已有主题相似度大于阈值，将该文档加入到与它<strong>相似度最大</strong>的且<strong>大于一定阈值</strong>的主题中；</li><li>如果与所有已有主题相似度都小于阈值，则以该文档为聚类种子，建立新的主题类别；</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Single-pass-Clustering&quot;&gt;&lt;a href=&quot;#Single-pass-Clustering&quot; class=&quot;headerlink&quot; title=&quot;Single-pass Clustering&quot;&gt;&lt;/a&gt;Single-pass Clusteri
      
    
    </summary>
    
    
      <category term="Cluster" scheme="http://yoursite.com/categories/Cluster/"/>
    
    
      <category term="Cluster" scheme="http://yoursite.com/tags/Cluster/"/>
    
  </entry>
  
  <entry>
    <title>序列标注任务的准确率和召回率</title>
    <link href="http://yoursite.com/2021/01/26/20210126-%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/"/>
    <id>http://yoursite.com/2021/01/26/20210126-%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/</id>
    <published>2021-01-26T01:58:00.000Z</published>
    <updated>2021-01-26T02:53:37.930Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>引：<a href="https://segmentfault.com/a/1190000021975136" target="_blank" rel="noopener">https://segmentfault.com/a/1190000021975136</a></p></blockquote><h2 id="序列标注的准确率和召回率"><a href="#序列标注的准确率和召回率" class="headerlink" title="序列标注的准确率和召回率"></a>序列标注的准确率和召回率</h2><h3 id="命名实体识别"><a href="#命名实体识别" class="headerlink" title="命名实体识别"></a>命名实体识别</h3><h4 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h4><ul><li>准确率: accuracy = 预测对的元素个数/总的元素个数</li><li>查准率：precision = 预测正确的实体个数 / 预测的实体总个数</li><li>召回率：recall = 预测正确的实体个数 / 标注的实体总个数</li><li>F1值： F1 = 2*准确率*召回率 / (准确率 + 召回率)</li></ul><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>E.g</p><p>  在序列标注算法中，一般我们会形成如下的序列列表，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'O'</span>, <span class="string">'O'</span>, <span class="string">'B-MISC'</span>, <span class="string">'I-MISC'</span>, <span class="string">'B-MISC'</span>, <span class="string">'I-MISC'</span>, <span class="string">'O'</span>, <span class="string">'B-PER'</span>, <span class="string">'I-PER'</span>]</span><br></pre></td></tr></table></figure><p>序列标注算法的格式有BIO，IOBES，BMES等.</p><ul><li>B，即Begin，表示开始</li><li>I，即Intermediate，表示中间</li><li>E，即End，表示结尾</li><li>S，即Single，表示单个字符</li><li>O，即Other，表示其他，用于标记无关字符</li></ul><h4 id="·实体·和·标签·"><a href="#·实体·和·标签·" class="headerlink" title="·实体·和·标签·"></a>·实体·和·标签·</h4><p><strong>实体</strong>指的是从B开头标签开始的，同一类型的，非O的连续标签序列。如[‘B-MISC’, ‘I-MISC’, ‘I-MISC’].</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">y_true = </span><br><span class="line">[<span class="string">'O'</span>, <span class="string">'O'</span>, <span class="string">'O'</span>, <span class="string">'B-MISC'</span>, <span class="string">'I-MISC'</span>, <span class="string">'I-MISC'</span>, <span class="string">'O'</span>, <span class="string">'B-PER'</span>, <span class="string">'I-PER'</span>]</span><br><span class="line"></span><br><span class="line">y_pred = </span><br><span class="line">[<span class="string">'O'</span>, <span class="string">'O'</span>, <span class="string">'B-MISC'</span>, <span class="string">'I-MISC'</span>, <span class="string">'B-MISC'</span>, <span class="string">'I-MISC'</span>, <span class="string">'O'</span>, <span class="string">'B-PER'</span>, <span class="string">'I-PER'</span>]</span><br></pre></td></tr></table></figure><p>列表中一共有9个元素：’O’, ‘O’, ‘O’, ‘B-MISC’, ‘I-MISC’, ‘I-MISC’, ‘O’, ‘B-PER’, ‘I-PER’</p><p>预测对的元素个数有6个：’O’(yes), ‘O’(yes), ‘O’, ‘B-MISC’, ‘I-MISC’, ‘I-MISC’(yes), ‘O’(yes), ‘B-PER’(yes), ‘I-PER’(yes)</p><p>标注的实体总个数为2个: [‘B-MISC’, ‘I-MISC’, ‘I-MISC’], [‘B-PER’, ‘I-PER’]</p><p>预测的实体总个数为3个：[‘B-MISC’, ‘I-MISC’],[‘B-MISC’, ‘I-MISC’],[‘B-PER’, ‘I-PER’]</p><p>预测正确的实体个数为1个：[‘B-PER’, ‘I-PER’]</p><p>因此：precision=1/3, recall=1/2, f1=0.4</p><h4 id="seqeval"><a href="#seqeval" class="headerlink" title="seqeval"></a>seqeval</h4><p>一般的序列标注算法，是用<code>conlleval.pl</code>脚本实现，但这是用perl语言实现的。在Python中，也有相应的序列标注算法的模型效果评估的第三方模块，那就是<code>seqeval</code>，其官网网址为：<a href="https://pypi.org/project/seqeval/0.0.3/" target="_blank" rel="noopener">https://pypi.org/project/seqeval/0.0.3/</a> 。</p><p><code>seqeval</code>支持<code>BIO</code>，<code>IOBES</code>标注模式，可用于命名实体识别，词性标注，语义角色标注等任务的评估。</p><p>E.g</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> seqeval.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="keyword">from</span> seqeval.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="keyword">from</span> seqeval.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> seqeval.metrics <span class="keyword">import</span> recall_score</span><br><span class="line"><span class="keyword">from</span> seqeval.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">y_true = [<span class="string">'O'</span>, <span class="string">'O'</span>, <span class="string">'O'</span>, <span class="string">'B-MISC'</span>, <span class="string">'I-MISC'</span>, <span class="string">'I-MISC'</span>, <span class="string">'O'</span>, <span class="string">'B-PER'</span>, <span class="string">'I-PER'</span>]</span><br><span class="line">y_pred = [<span class="string">'O'</span>, <span class="string">'O'</span>, <span class="string">'B-MISC'</span>, <span class="string">'I-MISC'</span>, <span class="string">'B-MISC'</span>, <span class="string">'I-MISC'</span>, <span class="string">'O'</span>, <span class="string">'B-PER'</span>, <span class="string">'I-PER'</span>]</span><br><span class="line"></span><br><span class="line">print(<span class="string">"accuary: "</span>, accuracy_score(y_true, y_pred))</span><br><span class="line">print(<span class="string">"p: "</span>, precision_score(y_true, y_pred))</span><br><span class="line">print(<span class="string">"r: "</span>, recall_score(y_true, y_pred))</span><br><span class="line">print(<span class="string">"f1: "</span>, f1_score(y_true, y_pred))</span><br><span class="line">print(<span class="string">"classification report: "</span>)</span><br><span class="line">print(classification_report(y_true, y_pred))</span><br></pre></td></tr></table></figure><p>Output</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">accuary:  <span class="number">0.6666666666666666</span></span><br><span class="line">p:  <span class="number">0.3333333333333333</span></span><br><span class="line">r:  <span class="number">0.5</span></span><br><span class="line">f1:  <span class="number">0.4</span></span><br><span class="line">classification report: </span><br><span class="line">           precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">     MISC       <span class="number">0.00</span>      <span class="number">0.00</span>      <span class="number">0.00</span>         <span class="number">1</span></span><br><span class="line">      PER       <span class="number">1.00</span>      <span class="number">1.00</span>      <span class="number">1.00</span>         <span class="number">1</span></span><br><span class="line"></span><br><span class="line">micro avg       <span class="number">0.33</span>      <span class="number">0.50</span>      <span class="number">0.40</span>         <span class="number">2</span></span><br><span class="line">macro avg       <span class="number">0.50</span>      <span class="number">0.50</span>      <span class="number">0.50</span>         <span class="number">2</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> seqeval.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> seqeval.metrics <span class="keyword">import</span> precision_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> seqeval.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> seqeval.metrics <span class="keyword">import</span> recall_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> seqeval.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_true = [[<span class="string">'B'</span>,<span class="string">'I'</span>,<span class="string">'B'</span>,<span class="string">'I'</span>,<span class="string">'B'</span>,<span class="string">'I'</span>,<span class="string">'I'</span>,<span class="string">'I'</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_pred = [[<span class="string">'B'</span>,<span class="string">'I'</span>,<span class="string">'I'</span>,<span class="string">'I'</span>,<span class="string">'B'</span>,<span class="string">'I'</span>,<span class="string">'I'</span>,<span class="string">'I'</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">"accuary: "</span>, accuracy_score(y_true, y_pred))</span><br><span class="line">accuary:  <span class="number">0.875</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">"p: "</span>, precision_score(y_true, y_pred))</span><br><span class="line">p:  <span class="number">0.5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">"r: "</span>, recall_score(y_true, y_pred))</span><br><span class="line">r:  <span class="number">0.3333333333333333</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">"f1: "</span>, f1_score(y_true, y_pred))</span><br><span class="line">f1:  <span class="number">0.4</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="string">"classification report: "</span>)</span><br><span class="line">classification report: </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(classification_report(y_true, y_pred))</span><br><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           _       <span class="number">0.50</span>      <span class="number">0.33</span>      <span class="number">0.40</span>         <span class="number">3</span></span><br><span class="line"></span><br><span class="line">   micro avg       <span class="number">0.50</span>      <span class="number">0.33</span>      <span class="number">0.40</span>         <span class="number">3</span></span><br><span class="line">   macro avg       <span class="number">0.50</span>      <span class="number">0.33</span>      <span class="number">0.40</span>         <span class="number">3</span></span><br><span class="line">weighted avg       <span class="number">0.50</span>      <span class="number">0.33</span>      <span class="number">0.40</span>         <span class="number">3</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;引：&lt;a href=&quot;https://segmentfault.com/a/1190000021975136&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://segmentfault.com/a/1190000021
      
    
    </summary>
    
    
      <category term="NER" scheme="http://yoursite.com/categories/NER/"/>
    
    
      <category term="NER" scheme="http://yoursite.com/tags/NER/"/>
    
  </entry>
  
  <entry>
    <title>Hexo的Next主题翻页箭头显示为&lt;i class=&quot;fa fa-angle-right&quot;&gt;&lt;/i&gt;问题</title>
    <link href="http://yoursite.com/2021/01/24/20210124-Hexo%E7%9A%84Next%E4%B8%BB%E9%A2%98%E7%BF%BB%E9%A1%B5%E7%AE%AD%E5%A4%B4%E6%98%BE%E7%A4%BA%E4%B8%BAi-class=fa-fa-angle-righti%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2021/01/24/20210124-Hexo%E7%9A%84Next%E4%B8%BB%E9%A2%98%E7%BF%BB%E9%A1%B5%E7%AE%AD%E5%A4%B4%E6%98%BE%E7%A4%BA%E4%B8%BAi-class=fa-fa-angle-righti%E9%97%AE%E9%A2%98/</id>
    <published>2021-01-24T11:49:00.000Z</published>
    <updated>2021-01-24T12:00:10.590Z</updated>
    
    <content type="html"><![CDATA[<h2 id="出现问题"><a href="#出现问题" class="headerlink" title="出现问题"></a>出现问题</h2><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gmz15x1b6hj30cd01ka9v.jpg" alt=""></p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>修改代码：<code>themes\next\layout\_partials\pagination.swig</code></p><p>旧：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if page.prev or page.next %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">nav</span> <span class="attr">class</span>=<span class="string">"pagination"</span>&gt;</span></span><br><span class="line">    &#123;&#123;</span><br><span class="line">      paginator(&#123;</span><br><span class="line">        prev_text: '<span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fa fa-angle-left"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span>',</span><br><span class="line">        next_text: '<span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fa fa-angle-right"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span>',</span><br><span class="line">        mid_size: 1</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="name">nav</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><p>新：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if page.prev or page.next %&#125;</span><br><span class="line">  &lt;nav class&#x3D;&quot;pagination&quot;&gt;</span><br><span class="line">    &#123;&#123;</span><br><span class="line">      paginator(&#123;</span><br><span class="line">        prev_text: &#39;&lt;&#39;,</span><br><span class="line">        next_text: &#39;&gt;&#39;,</span><br><span class="line">        mid_size: 1</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;&#125;</span><br><span class="line">  &lt;&#x2F;nav&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;出现问题&quot;&gt;&lt;a href=&quot;#出现问题&quot; class=&quot;headerlink&quot; title=&quot;出现问题&quot;&gt;&lt;/a&gt;出现问题&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/008eGmZEly1gmz15x1b6hj
      
    
    </summary>
    
    
      <category term="hexo" scheme="http://yoursite.com/categories/hexo/"/>
    
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>概念辨析-Epoch,Batch,Iteration</title>
    <link href="http://yoursite.com/2021/01/24/20210124-%E6%A6%82%E5%BF%B5%E8%BE%A8%E6%9E%90-Epoch,Batch,Iteration/"/>
    <id>http://yoursite.com/2021/01/24/20210124-%E6%A6%82%E5%BF%B5%E8%BE%A8%E6%9E%90-Epoch,Batch,Iteration/</id>
    <published>2021-01-23T16:00:00.000Z</published>
    <updated>2021-01-25T02:46:35.463Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Epoch-Batch-Iteration"><a href="#Epoch-Batch-Iteration" class="headerlink" title="Epoch, Batch, Iteration"></a>Epoch, Batch, Iteration</h2><p><code>Epoch</code>: 将所有训练样本训练一次的过程，即一个完整的数据集(所有训练样本)在神经网络中都进行了一次正向传播和一次反向传播。</p><p><code>Batch</code>: 当一个Epoch的样本数量过于庞大，则需要将其分为多个小块(Batch)进行训练。一个epoch需要经历多个Iteration(每次Iteration为一个Batch的Iteration)来完成。</p><p><code>Iteration</code>: 训练一个Batch就是一次Iteration。</p><h2 id="梯度下降方式"><a href="#梯度下降方式" class="headerlink" title="梯度下降方式"></a>梯度下降方式</h2><p>(In one Epoch)</p><table><thead><tr><th>梯度下降方式</th><th>Training Set Size</th><th>Batch Size</th><th>Number of Batches</th></tr></thead><tbody><tr><td><code>BGD</code>批量梯度下降法</td><td>N</td><td>N</td><td>1</td></tr><tr><td><code>SGD</code>随机梯度下降法</td><td>N</td><td>1</td><td>N</td></tr><tr><td><code>Mini-Batch</code>小批量梯度下降法</td><td>N</td><td>B</td><td>$\frac{N}{B}$+1</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Epoch-Batch-Iteration&quot;&gt;&lt;a href=&quot;#Epoch-Batch-Iteration&quot; class=&quot;headerlink&quot; title=&quot;Epoch, Batch, Iteration&quot;&gt;&lt;/a&gt;Epoch, Batch, Iterati
      
    
    </summary>
    
    
      <category term="nlp" scheme="http://yoursite.com/categories/nlp/"/>
    
    
      <category term="nlp" scheme="http://yoursite.com/tags/nlp/"/>
    
  </entry>
  
  <entry>
    <title>My first blog</title>
    <link href="http://yoursite.com/2020/01/14/2020-01-14-My-first-blog/"/>
    <id>http://yoursite.com/2020/01/14/2020-01-14-My-first-blog/</id>
    <published>2020-01-14T14:32:24.000Z</published>
    <updated>2021-01-24T11:52:14.414Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">"Hello world"</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Hello-World&quot;&gt;&lt;a href=&quot;#Hello-World&quot; class=&quot;headerlink&quot; title=&quot;Hello World&quot;&gt;&lt;/a&gt;Hello World&lt;/h2&gt;&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;
      
    
    </summary>
    
    
      <category term="杂" scheme="http://yoursite.com/categories/%E6%9D%82/"/>
    
    
      <category term="杂" scheme="http://yoursite.com/tags/%E6%9D%82/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode-0 模版</title>
    <link href="http://yoursite.com/2019/11/30/2020-00-00-LeetCode-0-%E6%A8%A1%E7%89%88/"/>
    <id>http://yoursite.com/2019/11/30/2020-00-00-LeetCode-0-%E6%A8%A1%E7%89%88/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-07-21T11:10:04.575Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;
      
    
    </summary>
    
    
      <category term="leetcode" scheme="http://yoursite.com/categories/leetcode/"/>
    
    
      <category term="leetcode" scheme="http://yoursite.com/tags/leetcode/"/>
    
      <category term="Medium" scheme="http://yoursite.com/tags/Medium/"/>
    
  </entry>
  
</feed>
